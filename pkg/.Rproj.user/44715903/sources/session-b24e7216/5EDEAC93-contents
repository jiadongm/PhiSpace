#' Tune Nselect using cross-validation.
#'
#' @param reference
#' @param ncomp
#' @param impScores
#' @param YY
#' @param labPerSample
#' @param labelName
#' @param assayName
#' @param NselectLimits
#' @param gridSize
#' @param NselectV
#' @param Kfolds
#' @param seed
#' @param regMethod
#' @param mode
#' @param Ncores
#' @param normYY
#' @param labelCode
#'
#' @import ggplot2
CVTuneNselect <- function(reference,
                          ncomp,
                          impScores,
                          YY = NULL,
                          labPerSample = NULL,
                          labelName = NULL,
                          assayName = "logcounts",
                          NselectLimits = c(10, 15000),
                          gridSize = 30,
                          NselectV = NULL,
                          Kfolds = 5,
                          seed = 5202056,
                          regMethod = 'PCA',
                          mode = 'supervised',
                          Ncores = 5,
                          normYY = F,
                          labelCode = "-1,1")
{
  ## Prepare predictor
  XX <- as.matrix(t(assay(reference, assayName)))


  ## impScores can be a vector or a matrix (eg impScores for each class)
  impScores <- as.matrix(impScores)
  if(nrow(impScores) != nrow(reference)) stop("Incorrect dimension of impScores.")

  ## Order features by each column of impScores
  orderByCol <-
    apply(impScores, 2,
          function(x){
            names(x) <- rownames(impScores)
            names(sort(abs(x), decreasing = T))
          })

  ## Prepare NselectV
  if(is.null(NselectV)){

    NselectMax <- max(NselectLimits)
    NselectMin <- min(NselectLimits)

    # If min Nselect results in too few features, fewer than ncomp
    actualNselectMin <- length(
      unique(
        as.vector(
          orderByCol[1:NselectMin,]
        )
      )
    )
    if(ncomp > actualNselectMin){
      NselectMin <- ncomp
    }

    NselectV <-
      round(
        exp(
          seq(log(NselectMin), log(NselectMax), length.out = gridSize)
        )
      )
    NselectV <- unique(NselectV)

  }




  ## Prepare response: dummy matrix
  if(mode == "supervised" & is.null(YY)){

    if(is.null(labelName)) stop("Have to specify either labelName or YY.")

    Ytrain <- colData(reference)[,labelName]
    classLabels <- names(table(Ytrain))
    YY <- sapply(1:length(Ytrain),
                 function(x){

                   if(labelCode == "-1/+1"){

                     out <- as.numeric(classLabels == Ytrain[x])
                     out[out == 0] <- -1

                   } else {

                     out <- as.numeric(classLabels == Ytrain[x])

                   }

                   return(out)
                 })
    YY <- t(YY)
    dimnames(YY) <- list(rownames(XX), classLabels)
  }

  if(mode != "supervised" & is.null(YY)){
    stop("YY cannot be NULL for unsupervised mode.")
  }

  ## By default each sample has one label, eg cell type
  if(is.null(labPerSample)){
    labPerSample <- 1
  }

  ## CV
  # Create data partition
  set.seed(seed)
  Nsamples <- nrow(XX)
  allIdx <- 1:Nsamples # indices of all samples
  permuIdx <- sample(allIdx, Nsamples) # random permutation of allIdx
  foldSize <- floor(Nsamples/Kfolds) # input of split f below
  splitIdx <- split2(permuIdx, Kfolds)

  # Function defining what to do for k-th fold partition
  CVjob <- function(k){

    valIdx <- splitIdx[[k]]
    trainIdx <- setdiff(allIdx, valIdx)

    errs <- getErrNselect(
      NselectV = NselectV,
      orderByCol = orderByCol,
      ncomp = ncomp,
      XX = XX[trainIdx, ], YY = YY[trainIdx, ],
      XXtest = XX[valIdx, ], YYtest = YY[valIdx, ],
      labPerSample = labPerSample,
      regMethod = regMethod,
      assayName = assayName,
      normYY = normYY,
      mode = mode
    )

    return(errs)
  }


  # Parallel computing CV
  if(Ncores > 1){
    Ncores <- min(Ncores, parallel::detectCores()-1)
    err_re <- parallel::mclapply(1:Kfolds, FUN = CVjob, mc.cores = Ncores)
  } else {
    err_re <- lapply(1:Kfolds, FUN = CVjob)
  }
  errs <- Reduce(`+`, err_re)/length(err_re)

  # Select Nselect
  # whichCrit <- ifelse(mode=='supervised', 4, 1)
  # crit <- rownames(errs)[whichCrit]
  # Nselect <- NselectV[which.min(errs[crit,])]
  # selectFeat <- names(impScores[rank(-impScores) <= Nselect])





  ## Graphical output
  # if(graph.out){
  #   if(mode == 'supervised'){
  #     par(mfrow=c(4,1), mai = c(0,0.2,0.1,0.1), oma = c(4,1,0,0))
  #   } else {
  #     par(mfrow=c(3,1), mai = c(0,0.2,0.1,0.1), oma = c(4,1,0,0))
  #   }
  #   plot(NselectV, errs[1,], xaxt="n")
  #   abline(v = Nselect, lwd = 2, col = 'red')
  #   plot(NselectV, errs[2,], xaxt="n")
  #   abline(v = Nselect, lwd = 2, col = 'red')
  #   plot(NselectV, errs[3,], xaxt="n")
  #   if(mode != 'supervised') axis(1, at=NselectV, las=2)
  #   abline(v = Nselect, lwd = 2, col = 'red')
  #   if(mode == 'supervised'){
  #     plot(NselectV, errs[4,], xaxt="n")
  #     axis(1, at=NselectV, las=2)
  #     abline(v = Nselect, lwd = 2, col = 'red')
  #   }
  # }



  ### Plotting ----------------------------------------
  if(mode == "supervised"){


    errs <- errs %>%
      t() %>%
      as.data.frame() %>%
      dplyr::mutate(Nselect = NselectV)

    p <- errs %>%
      ggplot(mapping = aes(x = Nselect)) +
      scale_x_continuous(
        breaks = errs$Nselect,
        trans = "log",
        guide = guide_axis(angle = 90, n.dodge=2)
      )

    ## rescaleX and interceptX are used to scale and shift two ranges to the same

    ## Errors using normalised scores
    rescale1 <- diff(range(errs$overall))/diff(range(errs$balanced))
    intercep1 <- min(errs$balanced) - min(errs$overall) / rescale1
    p1 <-
      p +
      geom_line(mapping = aes(y = overall)) +
      geom_point(mapping = aes(y = overall)) +
      geom_line(mapping = aes(y = (balanced - intercep1) * rescale1), color = "blue") +
      geom_point(
        aes(y = (balanced - intercep1) * rescale1),
        color = "blue"
      ) +
      ggrepel::geom_text_repel(
        aes(
          y = (balanced - intercep1) * rescale1,
          label = Nselect
        ),
        color = "blue"
      ) +
      scale_y_continuous(
        "Overall",
        sec.axis = sec_axis(~./rescale1 + intercep1, name = "Balanced"),
      )  +
      theme(axis.line.y.right = element_line(color = "blue"),
            axis.ticks.y.right = element_line(color = "blue"),
            axis.text.y.right = element_text(color = "blue"),
            axis.title.y.right = element_text(color = "blue")
      ) +
      ggtitle("Classif errors - Original")

    # p2
    ## Error using non-normalised scores
    rescale2 <- diff(range(errs$overall_norm))/diff(range(errs$balanced_norm))
    intercep2 <- min(errs$balanced_norm) - min(errs$overall_norm) / rescale2
    p2 <-
      p +
      geom_line(mapping = aes(y = overall_norm)) +
      geom_point(mapping = aes(y = overall_norm)) +
      geom_line(mapping = aes(y = (balanced_norm - intercep2) * rescale2), color = "blue") +
      geom_point(
        aes(
          y = (balanced_norm - intercep2) * rescale2
        ),
        color = "blue"
      ) +
      ggrepel::geom_text_repel(
        aes(
          y = (balanced_norm - intercep2) * rescale2,
          label = Nselect
        ),
        color = "blue"
      ) +
      scale_y_continuous(
        "Overall - normalised",
        sec.axis = sec_axis(~./rescale2 + intercep2, name = "Balanced - normalised")
      )  +
      theme(axis.line.y.right = element_line(color = "blue"),
            axis.ticks.y.right = element_line(color = "blue"),
            axis.text.y.right = element_text(color = "blue"),
            axis.title.y.right = element_text(color = "blue")
      ) +
      ggtitle("Classif errors - Normalised")
    # p2
    p3 <-
      p +
      geom_line(mapping = aes(y = `Frob ratio`)) +
      geom_point(mapping = aes(y = `Frob ratio`)) +
      ylab("Scaled Frobenius") +
      ggtitle("Scaled Frobenius error")
    # p3
    p4 <-
      p +
      geom_line(mapping = aes(y = `inf norm`)) +
      geom_point(mapping = aes(y = `inf norm`)) +
      ylab("Inf norm") +
      ggtitle("Inf norm")
    print(p1 + p2 + p3 + p4 + patchwork::plot_layout(ncol = 2))
  } else {
    ## Prepare tibble for visualisation
    errs <- errs %>%
      t() %>%
      as.data.frame() %>%
      dplyr::mutate(Nselect = NselectV)

    p <- errs %>%
      ggplot(mapping = aes(x = Nselect)) +
      scale_x_continuous(
        breaks = errs$Nselect,
        trans = "log",
        guide = guide_axis(angle = 90, n.dodge=2)
      )


    p1 <-
      p +
      geom_line(mapping = aes(y = `Frob ratio`)) +
      geom_point(mapping = aes(y = `Frob ratio`)) +
      ylab("Frobenius ratio") +
      ggtitle("Frobenius ratio")
    p2 <-
      p +
      geom_line(mapping = aes(y = `inf norm`)) +
      geom_point(mapping = aes(y = `inf norm`)) +
      ylab("Inf norm") +
      ggtitle("Inf norm")
    print(p1 + p2 + patchwork::plot_layout(ncol = 2))
  }


  Nselect <- readline("What is your choice of Nselect? ")
  Nselect <- as.numeric(Nselect)
  selectFeat <- unique(
    as.vector(
      orderByCol[1:Nselect, ]
    )
  )

  return(
    list(
      XX = XX,
      YY = YY,
      ncomp = ncomp,
      impScores = impScores,
      orderByCol = orderByCol,
      tuneNfeatErrs = errs,
      selectFeat = selectFeat,
      Nselect = Nselect,
      NselectV = NselectV,
      ## Not essential
      regMethod = regMethod,
      assayName = assayName,
      mode = mode,
      normYY = normYY,
      normType = normType
    )
  )
}
